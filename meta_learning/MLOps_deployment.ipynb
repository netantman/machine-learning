{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Patterns - an iterative process\n",
    "Different cases call for different patterns\n",
    "- New feature/function/capability, i.e. no benchmark: capability to start with a smaller traffic and then ramp up\n",
    "- Replacing Human/Automation, i.e. benchmark available: \n",
    "    - run the new system in parallel with the benchmark first\n",
    "    - inspect the examples where new model and benchmark differ (which can be valuable for further improvement)\n",
    "    - again roll out in small steps\n",
    "\n",
    "Think of deployment of ML algorithm as a spectrum along human only, shadow mode, AI assistance, partial automation and full automation, rather than a 0-1 classification. The level of automation depends on the use case. For example, quick internet search may be infeasible or costly to keep human in the loop, while in financial market applications, concept drifts render it necessary for human to override.\n",
    "\n",
    "Some common best practices in deployment.\n",
    "- Always be able to ramp up or down gradually, with monitoring and QC.\n",
    "- Build fallback or guardrails, including the ability to rollback/roll out different models quickly\n",
    "- Somehow related to above, modulize the data pipeline and model deployment.\n",
    "- Ability to replay or backtest historical data to debug issues (maybe more a data pipeline issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checklist of questions for software engineering issues\n",
    "- Realtime or Batch: in both training and prediction\n",
    "- Cloud vs. Edge/Browser\n",
    "- Computing resources difference between research and deployment: hardware resources, ML package dependencies\n",
    "- Latency, throughputs: understood as whether the prediction speed suits your need\n",
    "- Logging\n",
    "- Security, privacy and ethical considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics to Monitor in prod\n",
    "It ususally takes a few tries to converge to the right set of metrics to monitor: reason to deployment and try it out in small traffic first\n",
    "- Software metrics: memory, compute, latency, throughput, server load\n",
    "- Input metrics - helping you understand the distribution of $X$ and $y|X$, to guard against domain shifts: number of missing values, descriptive statistics of features\n",
    "- Output metrics - helping you understand the general health of the machine learning system: frequency of null output, output breaching guardrails, metrics on the viability of the ML algo (e.g. accuracy or MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Introduction to Machine Learning in Production](https://www.coursera.org/learn/introduction-to-machine-learning-in-production?specialization=machine-learning-engineering-for-production-mlops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
