{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification\n",
    "\n",
    "$$X=AS+\\epsilon,$$ \n",
    "\n",
    "where $X\\in\\mathbb{R}^p$, $A\\in\\mathbb{R}^{p\\times q}$ is called factor loading, $S\\in\\mathbb{R}^q$ are the common source of variation and $\\epsilon\\in\\mathbb{R}^p$ are idyosyncratic variables. Here $S$ and $\\epsilon$ are modeled as standard Gaussian random variables, and the model is fit by maximum likelihood. It describes the covariance matrix structure\n",
    "\n",
    "$$\\Sigma=AA^{\\top}+D_{\\epsilon},$$\n",
    "\n",
    "where $D_{\\epsilon}=diag[Var(\\epsilon_1),\\dots, Var(\\epsilon_p)]$.\n",
    "\n",
    "Note that there is an identifiability issue of factor analysis. That is, the expression is equivalent between $A$ and $AR$ for any rotational matrix $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants and Generalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factor analysis provides a low-rank approximation to the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation to Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor analysis has a strong relation to PCA.\n",
    "- If the $Var(\\epsilon)$ are all assumed to be equal, the leading $q$ components of the SVD identify the subspace determined by $A$\n",
    "- Because of the uncorrelated disturbances $\\epsilon$, factor analysis can be seen to be more about modeling the correlation structure of $X$ rather than the covariance structure, in that the form of $\\Sigma=AA^{\\top}+D_{\\epsilon}$ still holds for the correlation matrix with different $A$ and $D$.\n",
    "- When $D_{\\epsilon}$ has all equal diagonal values, it is call 'probabilistic PCA' or `PPCA` in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Independent Factor Analysis](ICA.ipynb) or ICA also uses the latent variable approach. But rather than assuming uncorrelated and Gaussian $S$ as in factor analysis, ICA assumes non-Gaussian, independent variables $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one [example](http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py) in sklearn document that shows if we fit a homogeneous-variance factor-analysis model to an actually heterogenous-variance data, it tends to overfit the number of components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Details and Practical Tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Factor Analysis in `sklearn`**\n",
    "\n",
    "FactorAnalysis performs a maximum likelihood estimate of the so-called loading matrix, the transformation of the latent variables to the observed ones, using expectation-maximization (EM).\n",
    "\n",
    "The input and method interface of `sklearn.decomposition.FactorAnalysis` is quite similar to `sklearn.decomposition.PCA`. The notable difference is in two of its methods:\n",
    "\n",
    "- `score(X[, y])`: Compute the average log-likelihood of the samples\n",
    "- `score_samples(X)`: Compute the log-likelihood of each sample\n",
    "\n",
    "This score can be used to determine `n_component`, by just taking the maximum or doing CV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Interpretation, Metrics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "### Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
